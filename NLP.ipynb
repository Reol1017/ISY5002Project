{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re #re stands for the regular expression module, which provides a set of tools for matching and manipulating text patterns.\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROWNUM</th>\n",
       "      <th>Hospital</th>\n",
       "      <th>Eligibility Class</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Arrival Time</th>\n",
       "      <th>Severity Level</th>\n",
       "      <th>Deparment</th>\n",
       "      <th>Main Diagnosis</th>\n",
       "      <th>Discharge Time</th>\n",
       "      <th>Waiting Time (Minutes)</th>\n",
       "      <th>Length of Stay (Minutes)</th>\n",
       "      <th>Treatment Time(Minutes)</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>No Treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Royal Commission Health Services Program</td>\n",
       "      <td>ROYAL COMMISSION</td>\n",
       "      <td>Female</td>\n",
       "      <td>2023-12-13 13:17:48</td>\n",
       "      <td>Level Ⅳ</td>\n",
       "      <td>Emergency Medicine</td>\n",
       "      <td>Pain, unspecified</td>\n",
       "      <td>2023-12-13 16:43:00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Royal Commission Health Services Program</td>\n",
       "      <td>ROYAL COMMISSION</td>\n",
       "      <td>Female</td>\n",
       "      <td>2023-12-08 10:59:28</td>\n",
       "      <td>Level Ⅲ</td>\n",
       "      <td>Emergency Medicine</td>\n",
       "      <td>Low back pain</td>\n",
       "      <td>2023-12-08 12:50:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Royal Commission Health Services Program</td>\n",
       "      <td>ROYAL COMMISSION</td>\n",
       "      <td>Female</td>\n",
       "      <td>2023-11-05 14:03:02</td>\n",
       "      <td>Level Ⅲ</td>\n",
       "      <td>Emergency Medicine</td>\n",
       "      <td>Acute upper respiratory infection, unspecified</td>\n",
       "      <td>2023-11-05 14:54:00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Royal Commission Health Services Program</td>\n",
       "      <td>ROYAL COMMISSION</td>\n",
       "      <td>Female</td>\n",
       "      <td>2023-10-07 22:57:41</td>\n",
       "      <td>Level Ⅲ</td>\n",
       "      <td>Emergency Medicine</td>\n",
       "      <td>Epistaxis</td>\n",
       "      <td>2023-10-08 00:09:00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Royal Commission Health Services Program</td>\n",
       "      <td>ROYAL COMMISSION</td>\n",
       "      <td>Female</td>\n",
       "      <td>2023-10-21 21:32:17</td>\n",
       "      <td>Level Ⅳ</td>\n",
       "      <td>Emergency Medicine</td>\n",
       "      <td>Acute upper respiratory infection, unspecified</td>\n",
       "      <td>2023-10-21 23:10:00</td>\n",
       "      <td>56.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ROWNUM                                  Hospital Eligibility Class  Gender  \\\n",
       "0      1  Royal Commission Health Services Program  ROYAL COMMISSION  Female   \n",
       "1      2  Royal Commission Health Services Program  ROYAL COMMISSION  Female   \n",
       "2      3  Royal Commission Health Services Program  ROYAL COMMISSION  Female   \n",
       "3      4  Royal Commission Health Services Program  ROYAL COMMISSION  Female   \n",
       "4      5  Royal Commission Health Services Program  ROYAL COMMISSION  Female   \n",
       "\n",
       "          Arrival Time Severity Level           Deparment  \\\n",
       "0  2023-12-13 13:17:48        Level Ⅳ  Emergency Medicine   \n",
       "1  2023-12-08 10:59:28        Level Ⅲ  Emergency Medicine   \n",
       "2  2023-11-05 14:03:02        Level Ⅲ  Emergency Medicine   \n",
       "3  2023-10-07 22:57:41        Level Ⅲ  Emergency Medicine   \n",
       "4  2023-10-21 21:32:17        Level Ⅳ  Emergency Medicine   \n",
       "\n",
       "                                   Main Diagnosis       Discharge Time  \\\n",
       "0                               Pain, unspecified  2023-12-13 16:43:00   \n",
       "1                                   Low back pain  2023-12-08 12:50:00   \n",
       "2  Acute upper respiratory infection, unspecified  2023-11-05 14:54:00   \n",
       "3                                       Epistaxis  2023-10-08 00:09:00   \n",
       "4  Acute upper respiratory infection, unspecified  2023-10-21 23:10:00   \n",
       "\n",
       "   Waiting Time (Minutes)  Length of Stay (Minutes)  Treatment Time(Minutes)  \\\n",
       "0                    14.0                     205.0                    191.0   \n",
       "1                     7.0                     111.0                    104.0   \n",
       "2                    24.0                      51.0                     27.0   \n",
       "3                    26.0                      71.0                      0.0   \n",
       "4                    56.0                      98.0                     42.0   \n",
       "\n",
       "   Cluster  No Treatment  \n",
       "0        2             0  \n",
       "1        1             0  \n",
       "2        1             0  \n",
       "3        1             1  \n",
       "4        0             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "data = pd.read_csv('data_after_EDA.csv')\n",
    "# Print the first 5 rows of the dataframe.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                         pain unspecified\n",
      "1                                                back pain\n",
      "2                              upper respiratory infection\n",
      "3                                                epistaxis\n",
      "4                              upper respiratory infection\n",
      "                               ...                        \n",
      "97085                                   asthma unspecified\n",
      "97086                          upper respiratory infection\n",
      "97087                          upper respiratory infection\n",
      "97088    cutaneous abscess furuncle and carbuncle unspe...\n",
      "97089                          pain in limb multiple sites\n",
      "Name: Main Diagnosis, Length: 97090, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(data, columns=['Main Diagnosis'])\n",
    "\n",
    "# Step 1: Lowercase all the entries in the 'Main Diagnosis' column\n",
    "df['Main Diagnosis'] = df['Main Diagnosis'].str.lower()\n",
    "\n",
    "# Step 2: Handle missing values by replacing NaN or empty strings with \"Unknown\"\n",
    "df['Main Diagnosis'] = df['Main Diagnosis'].fillna('Unknown')\n",
    "\n",
    "# Step 3: Remove punctuation or special characters from the diagnoses\n",
    "df['Main Diagnosis'] = df['Main Diagnosis'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "\n",
    "# Step 4: Standardize some common diagnoses (as an example)\n",
    "df['Main Diagnosis'] = df['Main Diagnosis'].replace({\n",
    "    'acute upper respiratory infection unspecified': 'upper respiratory infection',\n",
    "    'low back pain': 'back pain',\n",
    "   \n",
    "})\n",
    "\n",
    "print(df['Main Diagnosis'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import spacy # to visualiza the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97090/97090 [09:30<00:00, 170.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Main Diagnosis  \\\n",
      "0                                       pain unspecified   \n",
      "1                                              back pain   \n",
      "2                            upper respiratory infection   \n",
      "3                                              epistaxis   \n",
      "4                            upper respiratory infection   \n",
      "...                                                  ...   \n",
      "97085                                 asthma unspecified   \n",
      "97086                        upper respiratory infection   \n",
      "97087                        upper respiratory infection   \n",
      "97088  cutaneous abscess furuncle and carbuncle unspe...   \n",
      "97089                        pain in limb multiple sites   \n",
      "\n",
      "                                   Main Diagnosis Tokens  \n",
      "0                                    [pain, unspecified]  \n",
      "1                                           [back, pain]  \n",
      "2                        [upper, respiratory, infection]  \n",
      "3                                            [epistaxis]  \n",
      "4                        [upper, respiratory, infection]  \n",
      "...                                                  ...  \n",
      "97085                              [asthma, unspecified]  \n",
      "97086                    [upper, respiratory, infection]  \n",
      "97087                    [upper, respiratory, infection]  \n",
      "97088  [cutaneous, abscess, furuncle, and, carbuncle,...  \n",
      "97089                  [pain, in, limb, multiple, sites]  \n",
      "\n",
      "[97090 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Tokenizer\n",
    "# Function to apply spaCy processing and tokenize the Main Diagnosis column\n",
    "def spacy_tokenizer(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "# Apply spaCy tokenizer to the 'Main Diagnosis' column\n",
    "tqdm.pandas()  \n",
    "df['Main Diagnosis Tokens'] = df['Main Diagnosis'].progress_apply(lambda x: spacy_tokenizer(str(x).lower()))\n",
    "\n",
    "# Display the tokenized diagnosis column\n",
    "print(df[['Main Diagnosis', 'Main Diagnosis Tokens']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing Stop Words: 100%|██████████| 97090/97090 [00:00<00:00, 327432.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Main Diagnosis  \\\n",
      "0                                       pain unspecified   \n",
      "1                                              back pain   \n",
      "2                            upper respiratory infection   \n",
      "3                                              epistaxis   \n",
      "4                            upper respiratory infection   \n",
      "...                                                  ...   \n",
      "97085                                 asthma unspecified   \n",
      "97086                        upper respiratory infection   \n",
      "97087                        upper respiratory infection   \n",
      "97088  cutaneous abscess furuncle and carbuncle unspe...   \n",
      "97089                        pain in limb multiple sites   \n",
      "\n",
      "                 Main Diagnosis Tokens Without Stopwords  \n",
      "0                                    [pain, unspecified]  \n",
      "1                                                 [pain]  \n",
      "2                        [upper, respiratory, infection]  \n",
      "3                                            [epistaxis]  \n",
      "4                        [upper, respiratory, infection]  \n",
      "...                                                  ...  \n",
      "97085                              [asthma, unspecified]  \n",
      "97086                    [upper, respiratory, infection]  \n",
      "97087                    [upper, respiratory, infection]  \n",
      "97088  [cutaneous, abscess, furuncle, carbuncle, unsp...  \n",
      "97089                      [pain, limb, multiple, sites]  \n",
      "\n",
      "[97090 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove the stop words\n",
    "#  Load spaCy stop words\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Function to remove stop words from the tokens\n",
    "def remove_stop_words(tokens):\n",
    "    return [token for token in tokens if token not in stop_words]\n",
    "\n",
    "# Apply tqdm to monitor the process\n",
    "tqdm.pandas(desc=\"Removing Stop Words\")\n",
    "\n",
    "# Apply the stop word removal function with a progress bar\n",
    "df['Main Diagnosis Tokens Without Stopwords'] = df['Main Diagnosis Tokens'].progress_apply(remove_stop_words)\n",
    "\n",
    "# Display the updated tokenized diagnosis column without stop words\n",
    "print(df[['Main Diagnosis', 'Main Diagnosis Tokens Without Stopwords']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lemmatizing Tokens: 100%|██████████| 97090/97090 [10:10<00:00, 159.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Main Diagnosis  \\\n",
      "0                                       pain unspecified   \n",
      "1                                              back pain   \n",
      "2                            upper respiratory infection   \n",
      "3                                              epistaxis   \n",
      "4                            upper respiratory infection   \n",
      "...                                                  ...   \n",
      "97085                                 asthma unspecified   \n",
      "97086                        upper respiratory infection   \n",
      "97087                        upper respiratory infection   \n",
      "97088  cutaneous abscess furuncle and carbuncle unspe...   \n",
      "97089                        pain in limb multiple sites   \n",
      "\n",
      "                               Main Diagnosis Lemmatized  \n",
      "0                                    [pain, unspecified]  \n",
      "1                                                 [pain]  \n",
      "2                        [upper, respiratory, infection]  \n",
      "3                                            [epistaxis]  \n",
      "4                        [upper, respiratory, infection]  \n",
      "...                                                  ...  \n",
      "97085                              [asthma, unspecified]  \n",
      "97086                    [upper, respiratory, infection]  \n",
      "97087                    [upper, respiratory, infection]  \n",
      "97088  [cutaneous, abscess, furuncle, carbuncle, unsp...  \n",
      "97089                       [pain, limb, multiple, site]  \n",
      "\n",
      "[97090 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Enable progress bar for pandas\n",
    "tqdm.pandas(desc=\"Lemmatizing Tokens\")\n",
    "\n",
    "# Function to apply spaCy lemmatization to tokens\n",
    "def lemmatize_tokens(tokens):\n",
    "    doc = nlp(\" \".join(tokens))  # Process the tokens into a single string\n",
    "    return [token.lemma_ for token in doc]  # Return the lemmatized tokens\n",
    "\n",
    "# Apply the lemmatization function with a progress bar\n",
    "df['Main Diagnosis Lemmatized'] = df['Main Diagnosis Tokens Without Stopwords'].progress_apply(lemmatize_tokens)\n",
    "\n",
    "# Display the lemmatized tokens\n",
    "print(df[['Main Diagnosis', 'Main Diagnosis Lemmatized']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import heapq\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 从 DataFrame 提取已经词形还原的诊断数据\n",
    "dataset = df['Main Diagnosis Lemmatized']\n",
    "\n",
    "# 创建词频字典\n",
    "word2count = {}\n",
    "for data in dataset:\n",
    "    for word in data:  # 直接迭代已词形还原的单词列表\n",
    "        if word not in word2count.keys():\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n",
    "\n",
    "# 使用 heapq 找出出现频率最高的100个词\n",
    "freq_words = heapq.nlargest(100, word2count, key=word2count.get)\n",
    "\n",
    "# 创建词袋模型的向量表示\n",
    "X = []\n",
    "for data in dataset:\n",
    "    vector = []\n",
    "    for word in freq_words:\n",
    "        if word in data:  # 直接检查该词是否在已词形还原的列表中\n",
    "            vector.append(1)\n",
    "        else:\n",
    "            vector.append(0)\n",
    "    X.append(vector)\n",
    "X = np.asarray(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Main Diagnosis        Main Diagnosis Lemmatized  \\\n",
      "0             pain unspecified              [pain, unspecified]   \n",
      "1                    back pain                           [pain]   \n",
      "2  upper respiratory infection  [upper, respiratory, infection]   \n",
      "3                    epistaxis                      [epistaxis]   \n",
      "4  upper respiratory infection  [upper, respiratory, infection]   \n",
      "\n",
      "                                          BoW_Vector  \n",
      "0  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "2  [0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "4  [0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n"
     ]
    }
   ],
   "source": [
    "# 将向量添加到 DataFrame\n",
    "df['BoW_Vector'] = list(X)\n",
    "\n",
    "# 打印更新后的 DataFrame 的部分内容来查看结果\n",
    "print(df[['Main Diagnosis', 'Main Diagnosis Lemmatized', 'BoW_Vector']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# rewrite the result of nlp to new csv\n",
    "vector_df = pd.DataFrame(df['BoW_Vector'].tolist(), columns=[f'word_{i}' for i in range(len(df['BoW_Vector'].iloc[0]))])\n",
    "\n",
    "new_df = pd.concat([df, vector_df], axis=1)\n",
    "\n",
    "new_df.to_csv('updated_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Main Diagnosis            Main Diagnosis Tokens  \\\n",
      "0             pain unspecified              [pain, unspecified]   \n",
      "1                    back pain                     [back, pain]   \n",
      "2  upper respiratory infection  [upper, respiratory, infection]   \n",
      "3                    epistaxis                      [epistaxis]   \n",
      "4  upper respiratory infection  [upper, respiratory, infection]   \n",
      "\n",
      "  Main Diagnosis Tokens Without Stopwords        Main Diagnosis Lemmatized  \\\n",
      "0                     [pain, unspecified]              [pain, unspecified]   \n",
      "1                                  [pain]                           [pain]   \n",
      "2         [upper, respiratory, infection]  [upper, respiratory, infection]   \n",
      "3                             [epistaxis]                      [epistaxis]   \n",
      "4         [upper, respiratory, infection]  [upper, respiratory, infection]   \n",
      "\n",
      "  Main Diagnosis Lemmatized Text               Processed Text  \\\n",
      "0               pain unspecified             pain unspecified   \n",
      "1                           pain                         pain   \n",
      "2    upper respiratory infection  upper respiratory infection   \n",
      "3                      epistaxis                    epistaxis   \n",
      "4    upper respiratory infection  upper respiratory infection   \n",
      "\n",
      "                                          BoW_Vector  word_0  word_1  word_2  \\\n",
      "0  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       1       0       0   \n",
      "1  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       0       0       0   \n",
      "2  [0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       0       1       1   \n",
      "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       0       0       0   \n",
      "4  [0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       0       1       1   \n",
      "\n",
      "   ...  word_90  word_91  word_92  word_93  word_94  word_95  word_96  \\\n",
      "0  ...        0        0        0        0        0        0        0   \n",
      "1  ...        0        0        0        0        0        0        0   \n",
      "2  ...        0        0        0        0        0        0        0   \n",
      "3  ...        0        0        0        0        0        0        0   \n",
      "4  ...        0        0        0        0        0        0        0   \n",
      "\n",
      "   word_97  word_98  word_99  \n",
      "0        0        0        0  \n",
      "1        0        0        0  \n",
      "2        0        0        0  \n",
      "3        0        0        0  \n",
      "4        0        0        0  \n",
      "\n",
      "[5 rows x 107 columns]\n"
     ]
    }
   ],
   "source": [
    "print(new_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
